# -*- coding: utf-8 -*-
"""dsai_practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16nsJZP0jzBLLavSFczaymO1ExApVetwg
"""

pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz

pip install pandas

pip install numpy

pip install spacy>=3.0

pip install scispacy

import pandas as pd

df = pd.read_csv('D_ICD_DIAGNOSES.csv')
df.head()

df.info()



import scispacy
import spacy
nlp = spacy.load("en_ner_bc5cdr_md")

nlp

def func(sample):
  
  #name entity recognition 
  doc = nlp(sample)
  vec = []
  for ent in doc.ents:
    vec.append(ent.text)
  
  return vec

feature = []

for i in range(0,14567):
 sample = df['long_title'][i]
 feature.append(func(sample))





df['key_feature_extracted'] = feature
df.head(1000)

pip install nltk

import nltk
nltk.download('punkt')
from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.tokenize import word_tokenize

text = "Nick likes to play football, however he is not too fond of tennis."
text_tokens = word_tokenize(text)

tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]

print(tokens_without_sw)

text = "Nick likes to play football, however he is not too fond of tennis."
text_tokens = word_tokenize(text)

tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]

print(tokens_without_sw)

x = ''
for i in tokens_without_sw:
  x = x + " " +i

x

nltk.download('wordnet')
nltk.download('omw-1.4')

from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()

def pipeline(sample):
  tokens = word_tokenize(sample)
  tokens_without_sw = [word for word in tokens if not word in stopwords.words()]
  tokens_lemma = [] 
  for j in tokens_without_sw:
     tokens_lemma.append(lemmatizer.lemmatize(j))
  x = ''
  for i in tokens_lemma:
   x = x + " " +i 

  return x

revised = []

for i in range(0,14567):
 sample = df['long_title'][i]
 revised.append(pipeline(sample))

df['desc_after_sw-removal_lemma'] = revised

df.head()

d = df

d = d.drop(['key_feature_extracted'], axis = 1)

d = d.drop(['icd9_code'], axis = 1)

d = d.drop(['row_id'], axis = 1)

d.head()

feature = []

for i in range(0,14567):
 sample = df['desc_after_sw-removal_lemma'][i]
 feature.append(func(sample))

d['key_feature_extracted'] = feature

d